{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "interracial-modification",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Obtaining file:///home/lobo/gym-snake\n",
      "Requirement already satisfied: gym in /home/lobo/.local/lib/python3.8/site-packages (from gym-snake==0.0.1) (0.18.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /home/lobo/.local/lib/python3.8/site-packages (from gym->gym-snake==0.0.1) (1.6.0)\n",
      "Requirement already satisfied: Pillow<=7.2.0 in /usr/lib/python3/dist-packages (from gym->gym-snake==0.0.1) (7.0.0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /home/lobo/.local/lib/python3.8/site-packages (from gym->gym-snake==0.0.1) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /home/lobo/.local/lib/python3.8/site-packages (from gym->gym-snake==0.0.1) (1.19.5)\n",
      "Requirement already satisfied: scipy in /home/lobo/.local/lib/python3.8/site-packages (from gym->gym-snake==0.0.1) (1.6.0)\n",
      "Requirement already satisfied: future in /home/lobo/.local/lib/python3.8/site-packages (from pyglet<=1.5.0,>=1.4.0->gym->gym-snake==0.0.1) (0.18.2)\n",
      "Installing collected packages: gym-snake\n",
      "  Attempting uninstall: gym-snake\n",
      "    Found existing installation: gym-snake 0.0.1\n",
      "    Uninstalling gym-snake-0.0.1:\n",
      "      Successfully uninstalled gym-snake-0.0.1\n",
      "  Running setup.py develop for gym-snake\n",
      "Successfully installed gym-snake\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install -e .\n",
    "\n",
    "import random\n",
    "import time\n",
    "import copy\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch as tc\n",
    "import torch.optim as opt\n",
    "\n",
    "import gym\n",
    "import gym_snake\n",
    "env = gym.make('snake-v0')\n",
    "\n",
    "from model import NN\n",
    "from core import CUDA_AVAILABLE, DEVICE\n",
    "\n",
    "from per_memory import PERMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "clinical-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Parameters\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "DISC_RATIO=0.95\n",
    "EPISODE_CNT=50000\n",
    "EPS_EXPONENT=2.6\n",
    "EPS_MAX=1.0\n",
    "EPS_MIN=0.1\n",
    "LEARN_FREQ=4\n",
    "LEARNING_RATE=1e-5\n",
    "REPLAY_MEM_SIZE = 500000\n",
    "STAT_DISPLAY_FREQ = 100\n",
    "SAVE_TEMP_FREQ = 400\n",
    "SAVE_VERSIONS_FREQ = EPISODE_CNT//10\n",
    "TARGET_UPD_FREQ = 1000\n",
    "VALIDATION_EPISODE_CNT = 100\n",
    "VALIDATION_FREQ = EPISODE_CNT//100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hidden-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "#set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "industrial-correction",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4000/50000(8.00%): LossAvg=0.0009 RwdAvg=-0.9561\n",
      "4100/50000(8.20%): LossAvg=0.0009 RwdAvg=-0.9299\n",
      "4200/50000(8.40%): LossAvg=0.0008 RwdAvg=-0.9230\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3b44e5210766>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mLEARN_FREQ\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mTARGET_UPD_FREQ\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mnet_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-3b44e5210766>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mopter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mopter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"CUDA: \",CUDA_AVAILABLE)\n",
    "net=NN().cuda() if CUDA_AVAILABLE else NN()\n",
    "net_target=copy.deepcopy(net)\n",
    "net_target.load_state_dict(net.state_dict())\n",
    "net.train()\n",
    "net_target.eval()\n",
    "\n",
    "opter=opt.Adam(net.parameters(),lr=LEARNING_RATE)\n",
    "perm = PERMemory(REPLAY_MEM_SIZE,alpha=0.0,beta=1)\n",
    "\n",
    "def train():\n",
    "    idxs,isws,bat=zip(*perm.sample(BATCH_SIZE,epi/EPISODE_CNT))\n",
    "    s1bat,abat,rbat,s2bat,dbat=zip(*bat)\n",
    "    abat=tc.tensor(abat).to(DEVICE)\n",
    "    rbat=tc.tensor(abat).to(DEVICE)\n",
    "    dbat=tc.tensor(abat).to(DEVICE)\n",
    "    s1bat=map(lambda x:tc.tensor(x).to(DEVICE),zip(*s1bat))\n",
    "    s2bat=map(lambda x:tc.tensor(x).to(DEVICE),zip(*s2bat))\n",
    "\n",
    "    q1=net(*s1bat)\n",
    "    with tc.no_grad():\n",
    "        q2=net_target(*s2bat)\n",
    "    x=q1.gather(1,abat.unsqueeze(dim=1)).squeeze()\n",
    "    y=rbat+DISC_RATIO*((1-dbat)*tc.max(q2,dim=1)[0])\n",
    "    \n",
    "    #MSE Loss with Importance Sampling Weight\n",
    "    loss=(tc.tensor(isws).to(DEVICE)*(x-y)**2).mean()\n",
    "    opter.zero_grad()\n",
    "    loss.backward()\n",
    "    opter.step()\n",
    "    losses.append(loss.cpu().detach().numpy())\n",
    "\n",
    "eps=EPS_MAX\n",
    "losses=[]\n",
    "rwdsums=[]\n",
    "for epi in range(1,EPISODE_CNT+1):\n",
    "    s1=env.reset()\n",
    "    done=False\n",
    "        \n",
    "    rwdsum=0\n",
    "    step=1\n",
    "    while not done:\n",
    "        q1=net(*map(lambda x:tc.tensor(x).to(DEVICE),s1))\n",
    "        actidx=(np.random.randint(0,3) if random.random()<eps else \n",
    "                np.argmax(q1.cpu().detach().numpy()))\n",
    "        val1=q1[0][actidx]\n",
    "        s2,rwd,done,info=env.step(actidx)\n",
    "        with tc.no_grad():\n",
    "            q2=net_target(*map(lambda x:tc.tensor(x).to(DEVICE),s2))\n",
    "        val2=rwd+DISC_RATIO*((1-done)*tc.max(q2,dim=1)[0])\n",
    "        td=val2-val1\n",
    "        perm.push(td,(s1,actidx,rwd,s2,int(done)))\n",
    "        \n",
    "        s1=s2\n",
    "        rwdsum+=rwd\n",
    "        \n",
    "        if step%LEARN_FREQ==0 and perm.cnt>=BATCH_SIZE:\n",
    "            train()\n",
    "        if step%TARGET_UPD_FREQ==0:\n",
    "            net_target.load_state_dict(net.state_dict())\n",
    "            net_target.eval()\n",
    "        step+=1\n",
    "            \n",
    "    rwdsums.append(rwdsum)\n",
    "    eps=min(EPS_MAX,max(EPS_MIN, ((EPISODE_CNT-epi)/EPISODE_CNT)**EPS_EXPONENT ))\n",
    "        \n",
    "    if epi%SAVE_TEMP_FREQ==0:\n",
    "        tc.save(net.state_dict(),'./netw.pt')\n",
    "        from IPython.display import clear_output\n",
    "        clear_output(wait=True)\n",
    "    if epi%STAT_DISPLAY_FREQ==0:\n",
    "        print(\"{}/{}({:.2f}%): LossAvg={:.4f} RwdAvg={:.4f}\".format(\n",
    "            epi,\n",
    "            EPISODE_CNT,\n",
    "            epi/EPISODE_CNT*100,\n",
    "            float(sum(losses))/len(losses),\n",
    "            float(sum(rwdsums))/len(rwdsums)))\n",
    "        rwdsums=[]\n",
    "        losses=[]\n",
    "\n",
    "\n",
    "#save\n",
    "tc.save(net.state_dict(),'./netw.pt')\n",
    "print(\"DONE!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import render_inline\n",
    "#load\n",
    "net=NN().cuda()\n",
    "net.load_state_dict(tc.load('./netw.pt'))\n",
    "net.eval();\n",
    "with tc.no_grad():\n",
    "    obs=env.reset()\n",
    "    while True:\n",
    "        res=net(*map(lambda x:tc.tensor(x).to(DEVICE),obs)).detach().squeeze().tolist()\n",
    "        obs, rwd, done, _ = env.step(res.index(max(res)))\n",
    "        #env.render()\n",
    "        render_inline(env)\n",
    "        if done:\n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}